# -*- coding: utf-8 -*-
"""WEB SCRAPER PYTHON.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eIJ_uwmi4RosYVrYgFJIqvg7YwSfBJdC
"""

import requests
from bs4 import BeautifulSoup

def scrape_quotes_with_tags(url):
    # Send a GET request to the URL
    response = requests.get(url)
    print("\nFirst, Check the Status Code of the Website to Extract : ",response.status_code,"\n")
    print("\" Here Status Code 200 represents the Website accepting us to Extract the Data from it.\nHence, we can continue Extracting data.\nIf status Code not equals 200, means the Website is not accepting your request to Extract the data on Copyright basis.\"\nNow, Here is the Question, What is Status Code!?\n\n")
    print("   Let's Learn about STATUS CODE DATA :\n1. Informational Responses   -     100 to 199\n2. Successful Responses   -     200 to 299\n3. Redirection Messages   -     300 to 399\n4. Client Error Responses   -     400 to 499\n5. Server Error Responses   -     500 to 599\n\nMoving Forward, Let's get what all we need to Extract,\n")

    # Check if the request was successful
    if response.status_code != 200:
        print('Failed to retrieve the webpage')
        return

    # Parse the HTML content using BeautifulSoup
    soup = BeautifulSoup(response.content, 'html.parser')


    # Find all the quote texts, authors, and tags
    quotes = soup.find_all('span', class_='text')
    authors = soup.find_all('small', class_='author')
    tags = soup.find_all('div', class_='tags')


    # Print the quotes, authors, and tags
    for i in range(len(quotes)):
        print('QUOTE      :  ', quotes[i].text)
        print('AUTHOR     :  ', authors[i].text)
        tags_list = tags[i].find_all('a', class_='tag')
        tag_texts = [tag.text for tag in tags_list]
        print('\"TAGS\"     :  ', ', '.join(tag_texts))
        print()
        # Print an empty line between each quote, author, and tags

if __name__ == '__main__':
    # Replace this URL with the URL of the website you want to scrape
    target_url = 'http://quotes.toscrape.com/'
    scrape_quotes_with_tags(target_url)
    print("\n\" WE HAVE SUCCESSFULLY SCRAPED EVERYTHING OUT FROM THE WEBPAGE, OVER AND OUT... \"")